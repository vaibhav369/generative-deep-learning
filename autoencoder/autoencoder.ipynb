{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vaibggup\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Dense, LeakyReLU, Flatten, Reshape, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_test), (y_train, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of data\n",
      "x_train: (60000, 28, 28)\n",
      "x_test: (60000,)\n",
      "y_train: (10000, 28, 28)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes of data')\n",
    "print('x_train:', x_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1:] # This is the size of the input image that our auto-encoder will be working with\n",
    "output_dim = input_dim # In an autoencoder, we want the output to be same as input (hence the name), and therefore\n",
    "                       # the same size\n",
    "conv_filter_nums = [32, 64, 64, 64]\n",
    "conv_kernel_sizes = [3, 3, 3, 3]\n",
    "conv_strides = [1, 2, 2, 1]\n",
    "\n",
    "deconv_filter_nums = [64, 64, 32, 1]\n",
    "deconv_kernel_sizes = [3, 3, 3, 3]\n",
    "deconv_strides = [1, 2, 2, 1]\n",
    "\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=input_dim, name='encoder_input')\n",
    "x = encoder_input\n",
    "\n",
    "assert len(conv_filter_nums) == len(conv_kernel_sizes) == len(conv_strides)\n",
    "n_conv_layers = len(conv_filter_nums)\n",
    "\n",
    "for i in range(n_conv_layers):\n",
    "    conv_layer = Conv2D(filters=conv_filter_nums[i],\n",
    "                        kernel_size=conv_kernel_sizes[i],\n",
    "                        strides=conv_strides[i],\n",
    "                        padding='same',\n",
    "                        name='encoder_conv_' + str(i))\n",
    "    x = conv_layer(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "x = Flatten()(x)\n",
    "\n",
    "encoder_output = Dense(latent_dim, name='encoder_output')(x)\n",
    "\n",
    "encoder = Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "=================================================================\n",
      "Total params: 98,946\n",
      "Trainable params: 98,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "\n",
    "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "assert len(deconv_filter_nums) == len(deconv_kernel_sizes) == len(deconv_strides)\n",
    "n_deconv_layers = len(deconv_filter_nums)\n",
    "\n",
    "for i in range(n_deconv_layers):\n",
    "    deconv_layer = Conv2DTranspose(filters=deconv_filter_nums[i],\n",
    "                                   kernel_size=deconv_kernel_sizes[i],\n",
    "                                   strides=deconv_strides[i],\n",
    "                                   padding='same',\n",
    "                                   name='decoder_conv_' + str(i))\n",
    "    x = deconv_layer(x)\n",
    "    if i < n_deconv_layers - 1:\n",
    "        x = LeakyReLU()(x)\n",
    "    else:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "decoder_output = x                \n",
    "decoder = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_0 (Conv2DTransp (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_1 (Conv2DTransp (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_2 (Conv2DTransp (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_3 (Conv2DTransp (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input = encoder_input\n",
    "autoencoder_output = decoder(encoder_output)\n",
    "\n",
    "autoencoder = Model(autoencoder_input, autoencoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 28, 28, 1)         102017    \n",
      "=================================================================\n",
      "Total params: 200,963\n",
      "Trainable params: 200,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "\n",
    "optimizer = Adam(lr=0.0005)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=r_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 20\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath='autoencoder_' + str(latent_dim) + '.hdf5', monitor='loss', verbose=1), \n",
    "             EarlyStopping(monitor='loss', patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 520s 9ms/step - loss: 0.0491\n",
      "\n",
      "Epoch 00001: saving model to autoencoder_2.hdf5\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 516s 9ms/step - loss: 0.0447\n",
      "\n",
      "Epoch 00002: saving model to autoencoder_2.hdf5\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 542s 9ms/step - loss: 0.0436 0s - l\n",
      "\n",
      "Epoch 00003: saving model to autoencoder_2.hdf5\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 555s 9ms/step - loss: 0.0430\n",
      "\n",
      "Epoch 00004: saving model to autoencoder_2.hdf5\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 536s 9ms/step - loss: 0.0425\n",
      "\n",
      "Epoch 00005: saving model to autoencoder_2.hdf5\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 537s 9ms/step - loss: 0.0422\n",
      "\n",
      "Epoch 00006: saving model to autoencoder_2.hdf5\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 551s 9ms/step - loss: 0.0420\n",
      "\n",
      "Epoch 00007: saving model to autoencoder_2.hdf5\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 527s 9ms/step - loss: 0.0418\n",
      "\n",
      "Epoch 00008: saving model to autoencoder_2.hdf5\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 586s 10ms/step - loss: 0.0416\n",
      "\n",
      "Epoch 00009: saving model to autoencoder_2.hdf5\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 518s 9ms/step - loss: 0.0414\n",
      "\n",
      "Epoch 00010: saving model to autoencoder_2.hdf5\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 493s 8ms/step - loss: 0.0412\n",
      "\n",
      "Epoch 00011: saving model to autoencoder_2.hdf5\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 523s 9ms/step - loss: 0.0410 0s - loss\n",
      "\n",
      "Epoch 00012: saving model to autoencoder_2.hdf5\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 535s 9ms/step - loss: 0.0410 0s - \n",
      "\n",
      "Epoch 00013: saving model to autoencoder_2.hdf5\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 553s 9ms/step - loss: 0.0408\n",
      "\n",
      "Epoch 00014: saving model to autoencoder_2.hdf5\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 548s 9ms/step - loss: 0.0408\n",
      "\n",
      "Epoch 00015: saving model to autoencoder_2.hdf5\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 617s 10ms/step - loss: 0.0407\n",
      "\n",
      "Epoch 00016: saving model to autoencoder_2.hdf5\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 594s 10ms/step - loss: 0.0406\n",
      "\n",
      "Epoch 00017: saving model to autoencoder_2.hdf5\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 666s 11ms/step - loss: 0.0405\n",
      "\n",
      "Epoch 00018: saving model to autoencoder_2.hdf5\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8709s 145ms/step - loss: 0.0404\n",
      "\n",
      "Epoch 00019: saving model to autoencoder_2.hdf5\n",
      "Epoch 20/20\n",
      "39768/60000 [==================>...........] - ETA: 4:15 - loss: 0.0402"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x=x_train,\n",
    "                          y=x_train, \n",
    "                          batch_size=batch_size,\n",
    "                          epochs=num_epochs,\n",
    "                          callbacks=callbacks,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a random image to check if we are generating something relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_plot_index = np.random.randint(x_train.shape[0])\n",
    "\n",
    "img_to_plot = x_train[img_to_plot_index]\n",
    "generated_image = autoencoder.predict(np.expand_dims(img_to_plot, 0))[0]\n",
    "\n",
    "img_to_plot = np.squeeze(img_to_plot)\n",
    "generated_image = np.squeeze(generated_image)\n",
    "\n",
    "print(img_to_plot.shape)\n",
    "print(generated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img_to_plot)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Generated Image')\n",
    "plt.imshow(generated_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
