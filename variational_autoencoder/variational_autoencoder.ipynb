{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Conv2D, Conv2DTranspose, Flatten, Reshape, BatchNormalization\n",
    "from keras.layers import LeakyReLU, Dropout, Lambda, Input, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :-\n",
      "x_train; (60000, 28, 28)\n",
      "y_train: (60000,)\n",
      "x_test: (10000, 28, 28)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes :-')\n",
    "print('x_train;', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :-\n",
      "x_train; (60000, 28, 28, 1)\n",
      "y_train: (60000,)\n",
      "x_test: (10000, 28, 28, 1)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes :-')\n",
    "print('x_train;', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder and Decoder Definition for Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_num_filters = [32, 64, 64, 64]\n",
    "encoder_kernel_sizes = [3, 3, 3, 3]\n",
    "encoder_strides = [1, 2, 2, 1]\n",
    "\n",
    "decoder_num_filters = [64, 64, 32, 1]\n",
    "decoder_kernel_sizes = [3, 3, 3, 3]\n",
    "decoder_strides = [1, 2, 2, 1]\n",
    "\n",
    "batch_normalization = True\n",
    "dropout = True\n",
    "\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 21:50:29.802012 140666508252992 deprecation_wrapper.py:119] From /home/vaibhav/projects/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0903 21:50:29.803824 140666508252992 deprecation_wrapper.py:119] From /home/vaibhav/projects/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0903 21:50:29.854305 140666508252992 deprecation_wrapper.py:119] From /home/vaibhav/projects/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0903 21:50:29.855887 140666508252992 deprecation_wrapper.py:119] From /home/vaibhav/projects/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0903 21:50:29.921887 140666508252992 deprecation_wrapper.py:119] From /home/vaibhav/projects/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0903 21:50:30.015455 140666508252992 deprecation.py:506] From /home/vaibhav/projects/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=x_train.shape[1:], name='encoder_input')\n",
    "x = encoder_input\n",
    "\n",
    "for filter_num, kernel_size, stride in zip(encoder_num_filters, encoder_kernel_sizes, encoder_strides):\n",
    "    conv_layer = Conv2D(filters=filter_num,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=stride,\n",
    "                        padding='same')\n",
    "    x = conv_layer(x)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    if dropout:\n",
    "        x = Dropout(rate=0.25)(x)\n",
    "\n",
    "shape_before_flatten = K.int_shape(x)[1:]\n",
    "x = Flatten()(x)\n",
    "\n",
    "mu = Dense(latent_dim, name='mu')(x)\n",
    "log_var = Dense(latent_dim, name='log_var')(x)\n",
    "\n",
    "# This will be useful for analyzing our model later\n",
    "encoder_mu_log_var = Model(encoder_input, (mu, log_var))\n",
    "\n",
    "def sampling(args):\n",
    "    mu, log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_var/2) * epsilon\n",
    "\n",
    "encoder_output = Lambda(sampling, name='encoder_output')([mu, log_var])\n",
    "encoder = Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 28, 28, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 28, 28, 32)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 64)   18496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 14, 14, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 64)   0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 64)     36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 64)     36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 64)     256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3136)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            6274        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            6274        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 106,116\n",
      "Trainable params: 105,668\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(latent_dim, ), name='decoder_input')\n",
    "x = Dense( np.prod(shape_before_flatten) )(decoder_input)\n",
    "x = Reshape( shape_before_flatten )(x)\n",
    "\n",
    "for i, (filter_num, kernel_size, stride) in enumerate(zip(decoder_num_filters, decoder_kernel_sizes, decoder_strides)):\n",
    "    deconv_layer = Conv2DTranspose(filters=filter_num,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   strides=stride,\n",
    "                                   padding='same')\n",
    "    x = deconv_layer(x)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if i < len(decoder_kernel_sizes) - 1:\n",
    "        x = LeakyReLU()(x)\n",
    "    else:\n",
    "        x = Activation('sigmoid')(x)\n",
    "    if dropout:\n",
    "        x = Dropout(rate=0.25)(x)\n",
    "\n",
    "decoder_output = x\n",
    "decoder = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,661\n",
      "Trainable params: 102,339\n",
      "Non-trainable params: 322\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input = encoder_input\n",
    "autoencoder_output = decoder( encoder(autoencoder_input) )\n",
    "\n",
    "autoencoder = Model(autoencoder_input, autoencoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 2)                 106116    \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 28, 28, 1)         102661    \n",
      "=================================================================\n",
      "Total params: 208,777\n",
      "Trainable params: 208,007\n",
      "Non-trainable params: 770\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
